{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9916512,"sourceType":"datasetVersion","datasetId":6093956}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-29T14:01:58.299596Z","iopub.execute_input":"2024-11-29T14:01:58.303574Z","iopub.status.idle":"2024-11-29T14:02:00.197947Z","shell.execute_reply.started":"2024-11-29T14:01:58.303511Z","shell.execute_reply":"2024-11-29T14:02:00.197198Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport glob\nimport os\n\n# Paths to folders and their corresponding output values\nfolder_mappings = {\n    '/kaggle/input/im-fault/0.5mm': 0,\n    '/kaggle/input/im-fault/1.0mm': 0,\n    '/kaggle/input/im-fault/1.5mm': 1,\n    '/kaggle/input/im-fault/2.0mm': 1,\n    '/kaggle/input/im-fault/normal': 0\n}\n\n# Parameters for downsampling\nsample_fraction = 0.1  # Retain 10% of rows from each file\n\n# Initialize an empty list to store DataFrames\ndataframes = []\n\n# Process each folder and its CSV files\nfor folder, output_value in folder_mappings.items():\n    csv_files = glob.glob(os.path.join(folder, '*.csv'))\n    \n    for file in csv_files:\n        # Read the file without assuming headers\n        df = pd.read_csv(file, header=None)\n        \n        # Downsample the file\n        downsampled_df = df.sample(frac=sample_fraction, random_state=42)\n        \n        # Add the output column\n        downsampled_df['output'] = output_value\n        \n        # Append the modified DataFrame to the list\n        dataframes.append(downsampled_df)\n\n# Concatenate all the downsampled DataFrames\nmerged_df = pd.concat(dataframes, ignore_index=True)\n\n# Add custom header columns\nmerged_df.columns = [\n    'rotation freq', 'uh_ax_vib', 'uh_rd_vib', 'uh_tg_vib',\n    'oh_ax_vib', 'oh_rd_vib', 'oh_tg_vib', 'microphone', 'output'\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:41:32.464898Z","iopub.execute_input":"2024-12-01T10:41:32.465999Z","iopub.status.idle":"2024-12-01T10:42:19.188614Z","shell.execute_reply.started":"2024-12-01T10:41:32.465952Z","shell.execute_reply":"2024-12-01T10:42:19.187874Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"\nfrom scipy.fft import fft\nimport numpy as np\nimport pandas as pd\n\n# Function to apply FFT to a specific column in the DataFrame\ndef apply_fft_scipy(df, column_name):\n    # Perform FFT on the column data\n    fft_values = fft(df[column_name])\n    # Return only the magnitude of the FFT result\n    return np.abs(fft_values)\n\n# Columns to apply FFT (excluding the 'output' column)\ndata_columns = [\n    'rotation freq', 'uh_ax_vib', 'uh_rd_vib', 'uh_tg_vib',\n    'oh_ax_vib', 'oh_rd_vib', 'oh_tg_vib', 'microphone'\n]\n\n# Create an empty dictionary to store FFT results\nfft_data = {}\n\n# Apply FFT to each column and store in the dictionary\nfor col in data_columns:\n    fft_data[f'{col}_fft'] = apply_fft_scipy(merged_df, col)[:len(merged_df)]\n\n# Convert the dictionary to a new DataFrame\nfft_df = pd.DataFrame(fft_data)\n\n# Copy the 'output' column to the new DataFrame\nfft_df['output'] = merged_df['output']\n\n# Check the FFT DataFrame\nprint(fft_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:48:03.798198Z","iopub.execute_input":"2024-12-01T10:48:03.798568Z","iopub.status.idle":"2024-12-01T10:48:06.384469Z","shell.execute_reply.started":"2024-12-01T10:48:03.798538Z","shell.execute_reply":"2024-12-01T10:48:06.383576Z"}},"outputs":[{"name":"stdout","text":"   rotation freq_fft  uh_ax_vib_fft  uh_rd_vib_fft  uh_tg_vib_fft  \\\n0        1004.343013   68804.753690     292.980677    3158.538155   \n1        3269.751824   13532.195716     460.327254     985.479991   \n2        6881.740197    4501.487223      28.316261    1064.720351   \n3        5881.330951    1959.230291    1579.416536     433.786726   \n4        4218.824797    1956.575544     687.398252     872.787272   \n\n   oh_ax_vib_fft  oh_rd_vib_fft  oh_tg_vib_fft  microphone_fft  output  \n0   71700.382050   18791.174820   66569.925957    80609.907232       0  \n1    6845.204759      78.532673   30839.765520     3903.642134       0  \n2   14313.868282    1017.411608   15442.677752      446.887554       0  \n3    7180.536977     165.598974    2747.267940      516.773715       0  \n4   11647.841365     280.065261   23563.294336      867.180183       0  \n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\n\n# Assuming merged_df is your dataframe\n# Separate features (X) and target (y)\nX = fft_df.drop('output', axis=1)  # Replace 'target_column' with the actual name\ny = merged_df['output']\n\n# Encoding categorical features if they exist in X\nX = X.apply(LabelEncoder().fit_transform)\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Define models\nmodels = {\n    'Logistic Regression': LogisticRegression(max_iter=1000),\n    'Random Forest': RandomForestClassifier(),\n    'XGBoost': XGBClassifier(),\n}\n\n# Initialize variables to store the best model and score\nbest_model = None\nbest_score = 0\n\n# Loop through models and evaluate them\nfor model_name, model in models.items():\n    # Train the model\n    model.fit(X_train, y_train)\n    \n    # Predict and evaluate the model\n    y_pred = model.predict(X_test)\n    score = accuracy_score(y_test, y_pred)\n    \n    print(f'{model_name} Accuracy: {score:.4f}')\n    \n    # Update the best model if necessary\n    if score > best_score:\n        best_score = score\n        best_model = model_name\n\n    print(f'\\nModel: {best_model} with Accuracy: {best_score:.4f}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:48:23.246996Z","iopub.execute_input":"2024-12-01T10:48:23.247687Z"}},"outputs":[{"name":"stdout","text":"Logistic Regression Accuracy: 0.6014\n\nModel: Logistic Regression with Accuracy: 0.6014\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}